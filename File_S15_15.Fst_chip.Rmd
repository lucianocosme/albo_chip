---
title: "Aedes albopictus SNP chip - FST estimates"
author: "Luciano V Cosme"
date: "`r Sys.Date()`"
output:
  html_document:
    highlight: breezedark
    css:
      - "styles.css"
    toc: yes
    toc_float: no
    toc_depth: 5
editor_options:
  markdown:
    wrap: 120
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  eval                        = TRUE,
  echo                        = TRUE,
  cache                       = TRUE, # tidy = TRUE,
  class.output                = "bg-success"
)
knitr::opts_knit$set(
  root.dir = rprojroot::find_rstudio_root_file()
)
```

## Libraries

```{r libraries, message=FALSE, results='hide'}
library(StAMPP)
library(ggplot2)
library(tidyverse)
library(adegenet)
library(here)
library(flextable)
library(officer)
library(reshape2)
library(dplyr)
library(tidyr)
library(geosphere)
library(flextable)
library(officer)
library(dartR)
library(MASS)
library(Cairo)
``` 

We can use different data sets to run our fst estimates.

```{r}
# Remove all objects from the environment
rm(list = ls())

# Run the garbage collector to free up memory
gc()

```


## 1. Intergenic SNPs

We can estimate Fst using only the neutral set of SNPs for populations with at least 4 individuals.

Create list of populations
```{bash}
awk '{print $1}' output/populations/snps_sets/neutral.fam | sort | uniq -c | awk '{print $2, $1}' | awk '$2 >= 4 {print}' | awk '{print $1}' > output/fst/pops_4fst.txt;
head  output/fst/pops_4fst.txt;
wc -l output/fst/pops_4fst.txt
```

We have 25 populations with 4 or more mosquitoes. We can convert to raw format and subset the bed file

```{bash}
plink \
--allow-extra-chr \
--keep-allele-order \
--bfile output/populations/snps_sets/neutral \
--keep-fam output/fst/pops_4fst.txt \
--recodeA \
--out output/fst/neutral \
--silent;
grep 'samples\|variants\|remaining' output/fst/neutral.log
```

Look at https://rdrr.io/cran/StAMPP/man/stamppFst.html for details of Fst estimations

```{r, eval=FALSE, message=FALSE, results='hide'}
neutral <-
  read.PLINK(
    here(
      "output", "fst", "neutral.raw"
    ),
    quiet = FALSE,
    chunkSize = 1000,
    parallel = require("parallel"),
    n.cores = 4
  )

summary(neutral)
```

Now lets convert the genlight object to Stampp format, and estimate pairwide Fst values

The command below would also work, but you can simplify it and put only the numbers:
genome_equal_2 <- stamppFst(neutral, nboots=100,  percent=95 + nclusters==10)

This chunk will take a couple minutes to run.
```{r, eval=FALSE}
# convert
neutral_2 <- stamppConvert(neutral, type="genlight")

# run stampp. If you want to run with bootstraps and nclusters use the HPC. It will run out of memory on a 32Gb laptop
neutral_3 <- stamppFst(neutral_2, 1, 95, 1)
```

Save it
```{r, eval=FALSE}
saveRDS(
  neutral_3, here(
    "output", "fst", "neutral.rds"
  )
)
```

To load it
```{r}
neutral_3 <- readRDS(
  here(
    "output", "fst", "neutral.rds"
  )
)
```


Now lets look at the object

```{r}
summary(neutral_3)
```

If you want you can save the fst values as csv.
```{r}
# Convert to data frame
neutral_df <- data.frame(neutral_3)

# Save it
write.csv(neutral_df, file = here("output", "fst", "neutral_df.csv"))
```

Check the Fst values
```{r}
head(neutral_df)
```

We will convert the data into a matrix.
```{r}
aa <- as.matrix(neutral_df)
aa[upper.tri(aa)] <- t(aa)[upper.tri(t(aa))]
head(aa)
```

Import sample locations
```{r}
sampling_loc <- readRDS(here("output", "populations", "sampling_loc.rds"))

# Create a named vector to map countries to regions
country_to_region <- c(
  "Bhutan" = "South Asia",
  "Cambodia" = "Southeast Asia",
  "China" = "East Asia",
  "India" = "South Asia",
  "Indonesia" = "Southeast Asia",
  "Japan" = "East Asia",
  "Malaysia" = "Southeast Asia",
  "Maldives" = "South Asia",
  "Nepal" = "South Asia",
  "Sri Lanka" = "South Asia",
  "Taiwan" = "East Asia",
  "Thailand" = "Southeast Asia",
  "Vietnam" = "Southeast Asia"
)

# Add the region to the data frame
sampling_loc$Region2 <- country_to_region[sampling_loc$Country]

# Arrange by region 
sampling_loc <- sampling_loc |>
  dplyr::arrange(
    Region2, Country
  )

# Check it
head(sampling_loc)
```

Order
```{r}
order_pops <- as.vector(sampling_loc$Abbreviation)
order_pops
```

Create vector with order of populations
```{r}
# Extract the populations that appear in neutral_df
populations_in_neutral <- colnames(neutral_df)

# Reorder the populations based on order_pops
poporder <- populations_in_neutral[populations_in_neutral %in% order_pops]

# Print the reordered populations
print(poporder)
```


Lets check if the matrix is symmetric.
```{r}
isSymmetric(aa)
```


Now lets order the matrix using poporder. We will also add NA on the upper left side of the matrix.
```{r}
aa <- aa[poporder, poporder]
aa[lower.tri(aa)] <- NA
```


Now we have to convert the matrix to a data frame to plot it with ggplot.

```{r}
pairfst.long <- melt(aa)
summary(pairfst.long)
```

Now lets plot the data with ggplot.
You can click in the little square on the top left of the plot to open it on a new window. It will have the right proportions.
```{r, fig.width=9, fig.height=8}
pairfst.f <- ggplot(pairfst.long, aes(Var1, Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  scale_fill_gradient(
    low = "white",
    high = "#71b6ff",
    name = "Fst",
    na.value = "white",
    limits = c(0, 0.5)
  ) +
  scale_x_discrete(position = "top") +
  theme_bw() +
  geom_text(aes(label = ifelse(
    is.na(value), "", formatC(value, digits = 2, format = "f")
  )), size = 3) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_text(hjust = 0)
  )
pairfst.f
```


```{r}
ggsave(
  filename = here("output", "fst", "fst_matrix_neutral.pdf"),
  pairfst.f,
  width = 10,
  height = 10,
  units = "in"
)
```

By country
```{r}
# Step 1: Map abbreviation to country
abbreviation_to_country <- sampling_loc %>% select(Abbreviation, Country)

# Step 2: Calculate mean Fst for each pair of countries

# Convert the matrix to a data frame and add row names as a new column
fst_df <- as.data.frame(as.matrix(neutral_df))
fst_df$Abbreviation1 <- rownames(fst_df)

# Gather columns into rows
fst_long <- fst_df %>% gather(key = "Abbreviation2", value = "Fst", -Abbreviation1)

# Merge with country mapping
fst_long <- merge(fst_long, abbreviation_to_country, by.x = "Abbreviation1", by.y = "Abbreviation")
fst_long <- merge(fst_long, abbreviation_to_country, by.x = "Abbreviation2", by.y = "Abbreviation", suffixes = c("_1", "_2"))

# Calculate mean Fst for each pair of countries
fst_summary <- fst_long %>% 
  group_by(Country_1, Country_2) %>% 
  summarize(Mean_Fst = mean(Fst, na.rm = TRUE), .groups = 'drop') %>% 
  filter(Country_1 != Country_2)

# Convert summary back to a matrix form, avoiding the use of tibbles for row names
fst_matrix_summary <- as.data.frame(spread(fst_summary, key = Country_2, value = Mean_Fst))
rownames(fst_matrix_summary) <- fst_matrix_summary$Country_1
fst_matrix_summary <- fst_matrix_summary[, -1]
fst_matrix_summary <- as.matrix(fst_matrix_summary)

# Make the matrix symmetric by averaging the off-diagonal elements
symmetric_fst_matrix <- matrix(nrow = nrow(fst_matrix_summary), ncol = ncol(fst_matrix_summary))
rownames(symmetric_fst_matrix) <- rownames(fst_matrix_summary)
colnames(symmetric_fst_matrix) <- colnames(fst_matrix_summary)

for(i in 1:nrow(fst_matrix_summary)) {
  for(j in i:nrow(fst_matrix_summary)) {
    if (i == j) {
      symmetric_fst_matrix[i, j] <- fst_matrix_summary[i, j]
    } else {
      avg_value <- mean(c(fst_matrix_summary[i, j], fst_matrix_summary[j, i]), na.rm = TRUE)
      symmetric_fst_matrix[i, j] <- avg_value
      symmetric_fst_matrix[j, i] <- avg_value
    }
  }
}

# Check if the matrix is symmetric
# print(isSymmetric(symmetric_fst_matrix))

# Your symmetric Fst matrix by country is now in symmetric_fst_matrix
print(symmetric_fst_matrix)
```


```{r}
symmetric_fst_matrix[lower.tri(symmetric_fst_matrix)] <- NA
print(symmetric_fst_matrix)
```


Now we have to convert the matrix to a data frame to plot it with ggplot.

```{r}
pairfst.long2 <- melt(symmetric_fst_matrix)
summary(pairfst.long2)
```

You can click in the little square on the top left of the plot to open it on a new window. It will have the right proportions.
```{r, fig.width=6, fig.height=5}
pairfst.f2 <- ggplot(pairfst.long2, aes(Var1, Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  scale_fill_gradient(
    low = "white",
    high = "#71b6ff",
    name = "Fst",
    na.value = "white",
    limits = c(0, 0.5)
  ) +
  scale_x_discrete(position = "top") +
  theme_bw() +
  geom_text(aes(label = ifelse(
    is.na(value), "", formatC(value, digits = 2, format = "f")
  )), size = 3) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_text(hjust = 1)
  )
pairfst.f2

ggsave(
  filename = here("output", "fst", "fst_matrix_neutral_by_country.pdf"),
  pairfst.f2, 
  width = 6,
  height = 5,
  units = "in"
)
```


Remove NAs and rename columns
```{r}
# remove NAs
fst2 <-
  pairfst.long |>
  drop_na()

# rename columns
fst2 <-
  fst2 |>
  dplyr::rename(pop1 = 1,
         pop2 = 2,
         fst  = 3)


# Split the data into two data frames, one for pop1 and one for pop2
df_pop1 <- fst2 |>
  dplyr::select(pop = pop1, fst)
df_pop2 <- fst2 |>
  dplyr::select(pop = pop2, fst)

# Combine the two data frames
df_combined <- bind_rows(df_pop1, df_pop2)

# Calculate the mean fst for each population
mean_fst <- df_combined |>
  group_by(pop) |>
  summarise(mean_fst = mean(fst))

print(mean_fst)
```

Merge
```{r}
fst3 <-
  sampling_loc |>
  left_join(
    mean_fst,
    by = c("Abbreviation" = "pop")
  ) |>
  drop_na() |>
  dplyr::select(
    -Region
  )

# Remove " Asia" from the Region2 column
fst3$Region2 <- gsub(" Asia", "", fst3$Region2)

# Rename the Region2 column to Region
fst3 <- fst3 |>
  dplyr::rename(Region = Region2)

# check output
head(fst3)
```

Mean by region
```{r}
# Group by Region and calculate the mean_fst by Region
region_means <- fst3 |>
  group_by(Region) |>
  summarize(mean_fst_by_region = round(mean(mean_fst, na.rm = TRUE), 2)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_region column to the fst3 tibble
fst3 <- fst3 |>
  left_join(region_means, by = "Region")

# Print the modified fst3 tibble
print(fst3)
```

Mean by country
```{r}
# Group by Country and calculate the mean_fst by Country
country_means <- fst3 |>
  group_by(Country) |>
  summarize(mean_fst_by_country = round(mean(mean_fst, na.rm = TRUE), 2)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_country column to the fst3 tibble
fst3 <- fst3 |>
  left_join(country_means, by = "Country")

# Print the modified fst3 tibble
print(fst3)
```

Mean by latitude
```{r}
# Add a new column to indicate whether the latitude is above or below 30N
fst3 <- fst3 |>
  mutate(Latitude_group = ifelse(Latitude >= 30, "Above 30N", "Below 30N"))

# Summarize the data by Latitude_group and calculate the mean_fst
summary_by_latitude <- fst3 |>
  group_by(Latitude_group) |>
  summarize(mean_fst_by_latitude = mean(mean_fst, na.rm = TRUE)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_latitude column to the fst3 tibble
fst3 <- fst3 |>
  left_join(summary_by_latitude, by = "Latitude_group")


# Rename columns
fst3 <- fst3 |>
  dplyr::rename(
    City = Pop_City
  )

# Print the modified fst3 tibble
print(fst3)
```

```{r}
fst4 <- fst3 |>
  dplyr::select(
    Latitude_group, mean_fst_by_latitude, Region, mean_fst_by_region, Country, mean_fst_by_country, City, Abbreviation, mean_fst,
  )

fst4 <- fst4 |>
  arrange(
    Latitude_group, Region, Country, City
  )

# Round
fst4 <- fst4 |>
  mutate_if(is.numeric, ~ round(., 2))

head(fst4)
```


```{r}
# Set theme if you want to use something different from the previous table
set_flextable_defaults(
  font.family = "Arial",
  font.size = 9,
  big.mark = ",",
  theme_fun = "theme_zebra" # try the themes: theme_alafoli(), theme_apa(), theme_booktabs(), theme_box(), theme_tron_legacy(), theme_tron(), theme_vader(), theme_vanilla(), theme_zebra()
)

# Then create the flextable object
flex_table <- flextable(fst4) |>
  set_caption(caption = as_paragraph(
    as_chunk(
      "Table 1. Fst values using intergenic SNPs.",
      props = fp_text_default(color = "#000000", font.size = 14)
    )
  ),
  fp_p = fp_par(text.align = "center", padding = 5))

# Print the flextable
flex_table
```

```{r}
# Initialize Word document
doc <- 
  read_docx() |>
  body_add_flextable(value = flex_table)

# Define the output path with 'here' library
output_path <- here(
  "output",
  "fst", 
  "fst_neutral_SNPS.docx"
  )

# Save the Word document
print(doc, target = output_path)
```

To make scatter plot
```{r}
# Group by Country and calculate the mean for mean_fst_by_country
aggregated_data <- fst4 |>
  dplyr::group_by(Country) |>
  dplyr::summarise(mean_fst = mean(mean_fst_by_country, na.rm = TRUE))

# save the data
saveRDS(aggregated_data, here(
  "output", "fst", "neutral_country.rds"
))

# Order the aggregated data
aggregated_data <- aggregated_data[order(aggregated_data$mean_fst), ]

# Assign a numeric index for plotting
aggregated_data$index <- 1:nrow(aggregated_data)

# Fit a linear model
lm_fit <- lm(mean_fst ~ index, data = aggregated_data)

# Predicted values from the linear model
aggregated_data$fitted_values <- predict(lm_fit)

ggplot(aggregated_data, aes(x = index, y = mean_fst)) +
  geom_point(aes(color = Country), size = 3) +
  geom_line(aes(y = fitted_values), color = "blue") +  # Fitted line
  labs(
    title = "Mean Fst by Country",
    x = "Ordered Countries",
    y = "Mean Fst Value"
  ) +
  scale_x_continuous(breaks = aggregated_data$index, labels = aggregated_data$Country) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")
```

Estimate distances
```{r}
# Grab the population names from the matrix aa
populations_with_fst <- colnames(aa)

# Subset the sampling_loc dataframe to only include populations with FST estimates
filtered_sampling_loc <- sampling_loc %>% filter(Abbreviation %in% populations_with_fst)

# Create an empty matrix to store the distances
n <- nrow(filtered_sampling_loc)
distance_matrix <- matrix(0, n, n)
rownames(distance_matrix) <- filtered_sampling_loc$Abbreviation
colnames(distance_matrix) <- filtered_sampling_loc$Abbreviation

# Calculate the distances
for (i in 1:n) {
  for (j in 1:n) {
    if (i != j) {
      coord1 <- c(filtered_sampling_loc$Longitude[i], filtered_sampling_loc$Latitude[i])
      coord2 <- c(filtered_sampling_loc$Longitude[j], filtered_sampling_loc$Latitude[j])
      distance_matrix[i, j] <- distHaversine(coord1, coord2) / 1000 # distance in km
    }
  }
}

# Print the distance matrix
head(distance_matrix)
```



Compare distance and FST

```{r}
# Fill lower triangle of 'aa' matrix
aa[lower.tri(aa)] <- t(aa)[lower.tri(aa)]

# Fill diagonal with 0 (or another value that makes sense in your context)
diag(aa) <- 0


# Combine 'aa' and 'distance_matrix'
data <- data.frame(Distance = as.vector(distance_matrix), FST = as.vector(aa))

# Add row and column indices for easier tracking
data$row_index <- rep(rownames(distance_matrix), each = ncol(distance_matrix))
data$col_index <- rep(colnames(distance_matrix), nrow(distance_matrix))

data <- data |>
  dplyr::arrange(
    Distance
  )
head(data)
```

Fit linear regression
```{r, fig.height=4, fig.width=6}
# Fit linear model
lm_model <- lm(FST ~ Distance, data = data)
equation_text <- sprintf("y = %.6fx + %.3f", coef(lm_model)[2], coef(lm_model)[1])
r2_text <- sprintf("R^2 = %.2f", summary(lm_model)$r.squared)

# source the plotting function
source(here("scripts", "analysis", "my_theme2.R"))


# Plot
ggplot(data, aes(x = Distance, y = FST)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("text", x = max(data$Distance) * 0.85, y = max(data$FST) * 0.95, label = paste(equation_text, r2_text, sep = "\n"), size = 4, color = "black") +
  labs(title = "FST vs Distance - All populations",
       x = "Distance (Km)",
       y = "FST") +
  scale_x_continuous(labels = scales::comma) + 
  theme_classic()

ggsave(
  filename = here("output", "fst", "fst_by_distance_all_samples.pdf"),
  width = 6,
  height = 4,
  units = "in"
)
```


Subset by country
Select coutries with at least 3 sampling localities
```{r}
countries_with_3_pops <- filtered_sampling_loc %>%
  group_by(Country) %>%
  filter(n() >= 3) %>%
  pull(Country) %>%
  unique()
countries_with_3_pops
```

Do test for each country
```{r}
results <- list()

for (country in countries_with_3_pops) {
  # Extract abbreviations for the country
  abbreviations <- filtered_sampling_loc %>%
    filter(Country == country) %>%
    pull(Abbreviation)
  
  # Subset the data
  subset_data <- data %>%
    filter(row_index %in% abbreviations & col_index %in% abbreviations)
  
  # Perform linear regression
  lm_model <- lm(FST ~ Distance, data = subset_data)
  results[[country]] <- list(
    equation = sprintf("y = %.5fx + %.3f", coef(lm_model)[2], coef(lm_model)[1]),
    r2 = sprintf("R^2 = %.2f", summary(lm_model)$r.squared)
  )
}

results
```

Merge the data
```{r}
data_merged <- data %>%
  left_join(filtered_sampling_loc[, c("Pop_City", "Country", "Abbreviation")], by = c("row_index" = "Abbreviation")) %>%
  rename(Country1 = Country) %>%
  left_join(filtered_sampling_loc[, c("Pop_City", "Country", "Abbreviation")], by = c("col_index" = "Abbreviation")) %>%
  select(-Pop_City.x, -Pop_City.y) %>%
  filter(Country1 == Country)  # Ensures the data is within the same country


# Filter to get the coutries with 3 or more sampling localities
countries_to_include <- c("China", "Japan", "Indonesia", "Thailand", "Vietnam")

# Filter
data_filtered <- data_merged %>%
  group_by(Country1) %>%
  filter(n() >= 3 & Country1 %in% countries_to_include) %>%
  ungroup()
```

Calculate the linear regression for each country
```{r}
regression_results <- data_filtered %>%
  group_by(Country1) %>%
  do(model = lm(FST ~ Distance, data = .)) %>%
  rowwise() %>%
  mutate(equation = sprintf("y = %.3fx + %.3f", coef(model)[2], coef(model)[1]),
         r2 = sprintf("R^2 = %.2f", summary(model)$r.squared))
```

Plot it
```{r, fig.height=8, fig.width=6}
ggplot(data_filtered, aes(x = Distance, y = FST)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ Country1, scales = "free", ncol = 2) +
  geom_text(data = regression_results, aes(label = paste(equation, r2, sep = "\n"), x = Inf, y = Inf), 
            vjust = 2, hjust = 2, size = 3.5, inherit.aes = FALSE) +
  labs(title = "FST vs Distance by Country",
       x = "Distance",
       y = "FST") +
  scale_x_continuous(labels = scales::comma) + 
  theme_bw()


ggsave(
  filename = here("output", "fst", "fst_by_distance_countries.pdf"),
  width = 6,
  height = 8,
  units = "in"
)
```

We can merge the FST and distance matrices
```{r}
# Ensure the matrices have the same names in the same order
common_names <- intersect(rownames(distance_matrix), rownames(aa))
sorted_names <- sort(common_names)

# Reorder the matrices
distance_matrix <- distance_matrix[sorted_names, sorted_names]
aa <- aa[sorted_names, sorted_names]

# Initialize the final merged matrix
merged_matrix <- matrix(NA, nrow = nrow(aa), ncol = ncol(aa))
rownames(merged_matrix) <- sorted_names
colnames(merged_matrix) <- sorted_names

# Fill the upper triangular part from aa
merged_matrix[upper.tri(merged_matrix, diag = FALSE)] <- aa[upper.tri(aa, diag = FALSE)]

# Fill the lower triangular part from distance_matrix
merged_matrix[lower.tri(merged_matrix, diag = FALSE)] <- distance_matrix[lower.tri(distance_matrix, diag = FALSE)]

# Format the matrix (Fst two decimals and distance in Km with zero decimals)
# Format the elements based on their position in the matrix
for(i in 1:nrow(merged_matrix)) {
  for(j in 1:ncol(merged_matrix)) {
    if (i < j) {
      # Upper triangular - Fst values with two decimal places
      merged_matrix[i, j] <- sprintf("%.2f", as.numeric(merged_matrix[i, j]))
    } else if (i > j) {
      # Lower triangular - Distance values with zero decimal places
      merged_matrix[i, j] <- sprintf("%.0f", as.numeric(merged_matrix[i, j]))
    }
  }
}

# Now the merged_matrix should be formatted as you need
print(merged_matrix)
```

```{r}
cities <- readRDS(here("output", "populations", "cities.rds"))
head(cities)
```

We can sort by distance
```{r}
# Calculate row-wise mean distances (excluding diagonal)
row_means <- rowMeans(distance_matrix, na.rm=TRUE)

# Sort row names by mean distances
sorted_names_by_distance <- names(sort(row_means))

# Reorder distance_matrix and aa matrices based on these sorted names
distance_matrix <- distance_matrix[sorted_names_by_distance, sorted_names_by_distance]
aa <- aa[sorted_names_by_distance, sorted_names_by_distance]

# Your existing code to initialize and fill the merged_matrix
merged_matrix <- matrix(NA, nrow = nrow(aa), ncol = ncol(aa))
rownames(merged_matrix) <- sorted_names_by_distance
colnames(merged_matrix) <- sorted_names_by_distance

merged_matrix[upper.tri(merged_matrix, diag = FALSE)] <- aa[upper.tri(aa, diag = FALSE)]
merged_matrix[lower.tri(merged_matrix, diag = FALSE)] <- distance_matrix[lower.tri(distance_matrix, diag = FALSE)]

# Formatting code with absolute value for upper triangular part
for(i in 1:nrow(merged_matrix)) {
  for(j in 1:ncol(merged_matrix)) {
    if (i < j) {
      merged_matrix[i, j] <- sprintf("%.2f", abs(as.numeric(merged_matrix[i, j])))
    } else if (i > j) {
      merged_matrix[i, j] <- sprintf("%.0f", as.numeric(merged_matrix[i, j]))
    }
  }
}

# Print the merged matrix
print(merged_matrix)
```

Make a table and save as word document
```{r}
# Convert the matrix to a data frame and add a column with row names
merged_df <- as.data.frame(merged_matrix)
merged_df$Population <- rownames(merged_matrix)

# Reorder columns to have RowNames as the first column
merged_df <- merged_df[, c("Population", colnames(merged_matrix))]


# Create a flextable object from the merged_matrix
ft <- qflextable(as.data.frame(merged_df))

ft

# Create a new Word document
doc <- read_docx()

# Add the flextable to the Word document
doc <- body_add_flextable(doc, ft)

# Save the Word document
print(doc, target =  here("output", "fst", "intergenic.docx"))
```

## 2. SNP set r2 0.01

```{r}
# Remove all objects from the environment
rm(list = ls())

# Run the garbage collector to free up memory
gc()
```


```{bash}
plink \
--allow-extra-chr \
--keep-allele-order \
--bfile output/populations/snps_sets/r2_0.01 \
--keep-fam output/fst/pops_4fst.txt \
--recodeA \
--out output/fst/r2_0.01 \
--silent;
grep 'samples\|variants\|remaining' output/fst/r2_0.01.log
```

Look at https://rdrr.io/cran/StAMPP/man/stamppFst.html for details of Fst estimations

```{r, eval=FALSE, message=FALSE, results='hide'}
r2_0.01 <-
  read.PLINK(
    here(
      "output", "fst", "r2_0.01.raw"
    ),
    quiet = FALSE,
    chunkSize = 1000,
    parallel = require("parallel"),
    n.cores = 4
  )

summary(r2_0.01)
```


This chunk will take a couple minutes to run.
```{r, eval=FALSE}
# convert
r2_0.01_2 <- stamppConvert(r2_0.01, type="genlight")

# run stampp. If you want to runn with bootstraps and nclusters use the HPC. It will run out of memory on a 32Gb laptop
r2_0.01_3 <- stamppFst(r2_0.01_2, 1, 95, 1)
```


Save it
```{r, eval=FALSE}
saveRDS(
  r2_0.01_3, here(
    "output", "fst", "r2_0.01.rds"
  )
)
```


To load it
```{r}
r2_0.01_3 <- readRDS(
  here(
    "output", "fst", "r2_0.01.rds"
  )
)
```


Now lets look at the object

```{r}
summary(r2_0.01_3)
```

If you want you can save the fst values as csv.
```{r}
# Convert to data frame
r2_0.01_df <- data.frame(r2_0.01_3)

# Save it
write.csv(r2_0.01_df, file = here("output", "fst", "r2_0.01_df.csv"))
```

Check the Fst values
```{r}
head(r2_0.01_df)
```


Now lets get the Fst values from the object albo3. It has the bootstraps, CI limits, p-values, and Fst values.
We will convert the data into a matrix.
```{r}
aa <- as.matrix(r2_0.01_df)
aa[upper.tri(aa)] <- t(aa)[upper.tri(t(aa))]
head(aa)
```

Import sample locations
```{r}
sampling_loc <- readRDS(here("output", "populations", "sampling_loc.rds"))

# Create a named vector to map countries to regions
country_to_region <- c(
  "Bhutan" = "South Asia",
  "Cambodia" = "Southeast Asia",
  "China" = "East Asia",
  "India" = "South Asia",
  "Indonesia" = "Southeast Asia",
  "Japan" = "East Asia",
  "Malaysia" = "Southeast Asia",
  "Maldives" = "South Asia",
  "Nepal" = "South Asia",
  "Sri Lanka" = "South Asia",
  "Taiwan" = "East Asia",
  "Thailand" = "Southeast Asia",
  "Vietnam" = "Southeast Asia"
)

# Add the region to the data frame
sampling_loc$Region2 <- country_to_region[sampling_loc$Country]

# Arrange by region 
sampling_loc <- sampling_loc |>
  dplyr::arrange(
    Region2, Country
  )

# Check it
head(sampling_loc)
```

Order
```{r}
order_pops <- as.vector(sampling_loc$Abbreviation)
order_pops
```

Create vector with order of populations
```{r}
# Extract the populations that appear in neutral_df
populations_in_r2_0.01 <- colnames(r2_0.01_df)

# Reorder the populations based on order_pops
poporder <- populations_in_r2_0.01[populations_in_r2_0.01 %in% order_pops]

# Print the reordered populations
print(poporder)
```



Lets check if the matrix is symmetric.
```{r}
isSymmetric(aa)
```


Now lets order the matrix using poporder. We will also add NA on the upper left side of the matrix.
```{r}
aa <- aa[poporder, poporder]
aa[lower.tri(aa)] <- NA
```


Now we have to convert the matrix to a data frame to plot it with the ggplot.

```{r}
pairfst.long <- melt(aa)
summary(pairfst.long)
```

Now lets plot the data with ggplot.
You can click in the little square on the top left of the plot to open it on a new window. It will have the right proportions.
```{r, fig.width=9, fig.height=8}
pairfst.f <- ggplot(pairfst.long, aes(Var1, Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  scale_fill_gradient(
    low = "white",
    high = "#71b6ff",
    name = "Fst",
    na.value = "white",
    limits = c(0, 0.5)
  ) +
  scale_x_discrete(position = "top") +
  theme_bw() +
  geom_text(aes(label = ifelse(
    is.na(value), "", formatC(value, digits = 2, format = "f")
  )), size = 3) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_text(hjust = 0)
  )
pairfst.f
```

```{r}
ggsave(
  filename = here("output", "fst", "fst_matrix_r2_0.01.pdf"),
  pairfst.f,
  width = 10,
  height = 10,
  units = "in"
)
```

By country
```{r}
# Step 1: Map abbreviation to country
abbreviation_to_country <- sampling_loc %>% select(Abbreviation, Country)

# Step 2: Calculate mean Fst for each pair of countries

# Convert the matrix to a data frame and add row names as a new column
fst_df <- as.data.frame(as.matrix(r2_0.01_df))
fst_df$Abbreviation1 <- rownames(fst_df)

# Gather columns into rows
fst_long <- fst_df %>% gather(key = "Abbreviation2", value = "Fst", -Abbreviation1)

# Merge with country mapping
fst_long <- merge(fst_long, abbreviation_to_country, by.x = "Abbreviation1", by.y = "Abbreviation")
fst_long <- merge(fst_long, abbreviation_to_country, by.x = "Abbreviation2", by.y = "Abbreviation", suffixes = c("_1", "_2"))

# Calculate mean Fst for each pair of countries
fst_summary <- fst_long %>% 
  group_by(Country_1, Country_2) %>% 
  summarize(Mean_Fst = mean(Fst, na.rm = TRUE), .groups = 'drop') %>% 
  filter(Country_1 != Country_2)

# Convert summary back to a matrix form, avoiding the use of tibbles for row names
fst_matrix_summary <- as.data.frame(spread(fst_summary, key = Country_2, value = Mean_Fst))
rownames(fst_matrix_summary) <- fst_matrix_summary$Country_1
fst_matrix_summary <- fst_matrix_summary[, -1]
fst_matrix_summary <- as.matrix(fst_matrix_summary)

# Make the matrix symmetric by averaging the off-diagonal elements
symmetric_fst_matrix <- matrix(nrow = nrow(fst_matrix_summary), ncol = ncol(fst_matrix_summary))
rownames(symmetric_fst_matrix) <- rownames(fst_matrix_summary)
colnames(symmetric_fst_matrix) <- colnames(fst_matrix_summary)

for(i in 1:nrow(fst_matrix_summary)) {
  for(j in i:nrow(fst_matrix_summary)) {
    if (i == j) {
      symmetric_fst_matrix[i, j] <- fst_matrix_summary[i, j]
    } else {
      avg_value <- mean(c(fst_matrix_summary[i, j], fst_matrix_summary[j, i]), na.rm = TRUE)
      symmetric_fst_matrix[i, j] <- avg_value
      symmetric_fst_matrix[j, i] <- avg_value
    }
  }
}

# Check if the matrix is symmetric
# print(isSymmetric(symmetric_fst_matrix))

# Your symmetric Fst matrix by country is now in symmetric_fst_matrix
print(symmetric_fst_matrix)
```


```{r}
symmetric_fst_matrix[lower.tri(symmetric_fst_matrix)] <- NA
print(symmetric_fst_matrix)
```


Now we have to convert the matrix to a data frame to plot it with ggplot.

```{r}
pairfst.long2 <- melt(symmetric_fst_matrix)
summary(pairfst.long2)
```

You can click in the little square on the top left of the plot to open it on a new window. It will have the right proportions.
```{r, fig.width=6, fig.height=5}
pairfst.f2 <- ggplot(pairfst.long2, aes(Var1, Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  scale_fill_gradient(
    low = "white",
    high = "pink",
    name = "Fst",
    na.value = "white",
    limits = c(0, 0.5)
  ) +
  scale_x_discrete(position = "top") +
  theme_bw() +
  geom_text(aes(label = ifelse(
    is.na(value), "", formatC(value, digits = 2, format = "f")
  )), size = 3) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_text(hjust = 1)
  )
pairfst.f2

ggsave(
  filename = here("output", "fst", "fst_matrix_r2_0.01_by_country.pdf"),
  pairfst.f2, 
  width = 6,
  height = 5,
  units = "in"
)
```


Remove NAs and rename columns
```{r}
# remove NAs
fst2 <-
  pairfst.long |>
  drop_na()

# rename columns
fst2 <-
  fst2 |>
  dplyr::rename(pop1 = 1,
         pop2 = 2,
         fst  = 3)


# Split the data into two data frames, one for pop1 and one for pop2
df_pop1 <- fst2 |>
  dplyr::select(pop = pop1, fst)
df_pop2 <- fst2 |>
  dplyr::select(pop = pop2, fst)

# Combine the two data frames
df_combined <- bind_rows(df_pop1, df_pop2)

# Calculate the mean fst for each population
mean_fst <- df_combined |>
  group_by(pop) |>
  summarise(mean_fst = mean(fst))

print(mean_fst)
```

Merge
```{r}
fst3 <-
  sampling_loc |>
  left_join(
    mean_fst,
    by = c("Abbreviation" = "pop")
  ) |>
  drop_na() |>
  dplyr::select(
    -Region
  )

# Remove " Asia" from the Region2 column
fst3$Region2 <- gsub(" Asia", "", fst3$Region2)

# Rename the Region2 column to Region
fst3 <- fst3 |>
  dplyr::rename(Region = Region2)

# check output
head(fst3)
```

Mean by region
```{r}
# Group by Region and calculate the mean_fst by Region
region_means <- fst3 |>
  group_by(Region) |>
  summarize(mean_fst_by_region = round(mean(mean_fst, na.rm = TRUE), 2)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_region column to the fst3 tibble
fst3 <- fst3 |>
  left_join(region_means, by = "Region")

# Print the modified fst3 tibble
print(fst3)
```

Mean by country
```{r}
# Group by Country and calculate the mean_fst by Country
country_means <- fst3 |>
  group_by(Country) |>
  summarize(mean_fst_by_country = round(mean(mean_fst, na.rm = TRUE), 2)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_country column to the fst3 tibble
fst3 <- fst3 |>
  left_join(country_means, by = "Country")

# Print the modified fst3 tibble
print(fst3)
```

Mean by latitude
```{r}
# Add a new column to indicate whether the latitude is above or below 30N
fst3 <- fst3 |>
  mutate(Latitude_group = ifelse(Latitude >= 30, "Above 30N", "Below 30N"))

# Summarize the data by Latitude_group and calculate the mean_fst
summary_by_latitude <- fst3 |>
  group_by(Latitude_group) |>
  summarize(mean_fst_by_latitude = mean(mean_fst, na.rm = TRUE)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_latitude column to the fst3 tibble
fst3 <- fst3 |>
  left_join(summary_by_latitude, by = "Latitude_group")


# Rename columns
fst3 <- fst3 |>
  dplyr::rename(
    City = Pop_City
  )

# Print the modified fst3 tibble
print(fst3)
```

```{r}
fst4 <- fst3 |>
  dplyr::select(
    Latitude_group, mean_fst_by_latitude, Region, mean_fst_by_region, Country, mean_fst_by_country, City, Abbreviation, mean_fst,
  )

fst4 <- fst4 |>
  arrange(
    Latitude_group, Region, Country, City
  )

# Round
fst4 <- fst4 |>
  mutate_if(is.numeric, ~ round(., 2))

head(fst4)
```


```{r}
# Set theme if you want to use something different from the previous table
set_flextable_defaults(
  font.family = "Arial",
  font.size = 9,
  big.mark = ",",
  theme_fun = "theme_zebra" # try the themes: theme_alafoli(), theme_apa(), theme_booktabs(), theme_box(), theme_tron_legacy(), theme_tron(), theme_vader(), theme_vanilla(), theme_zebra()
)

# Then create the flextable object
flex_table <- flextable(fst4) |>
  set_caption(caption = as_paragraph(
    as_chunk(
      "Table 1. Fst values using SNPs after prunning with r2 0.01.",
      props = fp_text_default(color = "#000000", font.size = 14)
    )
  ),
  fp_p = fp_par(text.align = "center", padding = 5))

# Print the flextable
flex_table
```

```{r}
# Initialize Word document
doc <- 
  read_docx() |>
  body_add_flextable(value = flex_table)

# Define the output path with 'here' library
output_path <- here(
  "output",
  "fst", 
  "fst_r2_0.01_SNPS.docx"
  )

# Save the Word document
print(doc, target = output_path)
```

To make scatter plot
```{r}
# Group by Country and calculate the mean for mean_fst_by_country
aggregated_data <- fst4 |>
  dplyr::group_by(Country) |>
  dplyr::summarise(mean_fst = mean(mean_fst_by_country, na.rm = TRUE))

# save the data
saveRDS(aggregated_data, here(
  "output", "fst", "r2_0.01_country.rds"
))

# Order the aggregated data
aggregated_data <- aggregated_data[order(aggregated_data$mean_fst), ]

# Assign a numeric index for plotting
aggregated_data$index <- 1:nrow(aggregated_data)

# Fit a linear model
lm_fit <- lm(mean_fst ~ index, data = aggregated_data)

# Predicted values from the linear model
aggregated_data$fitted_values <- predict(lm_fit)

ggplot(aggregated_data, aes(x = index, y = mean_fst)) +
  geom_point(aes(color = Country), size = 3) +
  geom_line(aes(y = fitted_values), color = "blue") +  # Fitted line
  labs(
    title = "Mean Fst by Country",
    x = "Ordered Countries",
    y = "Mean Fst Value"
  ) +
  scale_x_continuous(breaks = aggregated_data$index, labels = aggregated_data$Country) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")
```

Estimate distances
```{r}
# Grab the population names from the matrix aa
populations_with_fst <- colnames(aa)

# Subset the sampling_loc dataframe to only include populations with FST estimates
filtered_sampling_loc <- sampling_loc %>% filter(Abbreviation %in% populations_with_fst)

# Create an empty matrix to store the distances
n <- nrow(filtered_sampling_loc)
distance_matrix <- matrix(0, n, n)
rownames(distance_matrix) <- filtered_sampling_loc$Abbreviation
colnames(distance_matrix) <- filtered_sampling_loc$Abbreviation

# Calculate the distances
for (i in 1:n) {
  for (j in 1:n) {
    if (i != j) {
      coord1 <- c(filtered_sampling_loc$Longitude[i], filtered_sampling_loc$Latitude[i])
      coord2 <- c(filtered_sampling_loc$Longitude[j], filtered_sampling_loc$Latitude[j])
      distance_matrix[i, j] <- distHaversine(coord1, coord2) / 1000 # distance in km
    }
  }
}

# Print the distance matrix
head(distance_matrix)
```


Compare distance and FST

```{r}
# Fill lower triangle of 'aa' matrix
aa[lower.tri(aa)] <- t(aa)[lower.tri(aa)]

# Fill diagonal with 0 (or another value that makes sense in your context)
diag(aa) <- 0


# Combine 'aa' and 'distance_matrix'
data <- data.frame(Distance = as.vector(distance_matrix), FST = as.vector(aa))

# Add row and column indices for easier tracking
data$row_index <- rep(rownames(distance_matrix), each = ncol(distance_matrix))
data$col_index <- rep(colnames(distance_matrix), nrow(distance_matrix))

head(data)
```

Fit linear regression
```{r, fig.height=4, fig.width=6}
# Fit linear model
lm_model <- lm(FST ~ Distance, data = data)
equation_text <- sprintf("y = %.6fx + %.3f", coef(lm_model)[2], coef(lm_model)[1])
r2_text <- sprintf("R^2 = %.2f", summary(lm_model)$r.squared)

# source the plotting function
source(here("scripts", "analysis", "my_theme2.R"))


# Plot
ggplot(data, aes(x = Distance, y = FST)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("text", x = max(data$Distance) * 0.85, y = max(data$FST) * 0.95, label = paste(equation_text, r2_text, sep = "\n"), size = 4, color = "black") +
  labs(title = "FST vs Distance - All populations",
       x = "Distance (Km)",
       y = "FST") +
  scale_x_continuous(labels = scales::comma) + 
  theme_classic()

ggsave(
  filename = here("output", "fst", "fst_by_distance_all_samples_LD1.pdf"),
  width = 6,
  height = 4,
  units = "in"
)
```


Subset by country
Select coutries with at least 3 sampling localities
```{r}
countries_with_3_pops <- filtered_sampling_loc %>%
  group_by(Country) %>%
  filter(n() >= 3) %>%
  pull(Country) %>%
  unique()
countries_with_3_pops
```

Do test for each country
```{r}
results <- list()

for (country in countries_with_3_pops) {
  # Extract abbreviations for the country
  abbreviations <- filtered_sampling_loc %>%
    filter(Country == country) %>%
    pull(Abbreviation)
  
  # Subset the data
  subset_data <- data %>%
    filter(row_index %in% abbreviations & col_index %in% abbreviations)
  
  # Perform linear regression
  lm_model <- lm(FST ~ Distance, data = subset_data)
  results[[country]] <- list(
    equation = sprintf("y = %.5fx + %.3f", coef(lm_model)[2], coef(lm_model)[1]),
    r2 = sprintf("R^2 = %.2f", summary(lm_model)$r.squared)
  )
}

results
```

Merge the data
```{r}
data_merged <- data %>%
  left_join(filtered_sampling_loc[, c("Pop_City", "Country", "Abbreviation")], by = c("row_index" = "Abbreviation")) %>%
  rename(Country1 = Country) %>%
  left_join(filtered_sampling_loc[, c("Pop_City", "Country", "Abbreviation")], by = c("col_index" = "Abbreviation")) %>%
  select(-Pop_City.x, -Pop_City.y) %>%
  filter(Country1 == Country)  # Ensures the data is within the same country


# Filter to get the coutries with 3 or more sampling localities
countries_to_include <- c("China", "Japan", "Indonesia", "Thailand", "Vietnam")

# Filter
data_filtered <- data_merged %>%
  group_by(Country1) %>%
  filter(n() >= 3 & Country1 %in% countries_to_include) %>%
  ungroup()
```

Calculate the linear regression for each country
```{r}
regression_results <- data_filtered %>%
  group_by(Country1) %>%
  do(model = lm(FST ~ Distance, data = .)) %>%
  rowwise() %>%
  mutate(equation = sprintf("y = %.3fx + %.3f", coef(model)[2], coef(model)[1]),
         r2 = sprintf("R^2 = %.2f", summary(model)$r.squared))
```

Plot it
```{r, fig.height=8, fig.width=6}
ggplot(data_filtered, aes(x = Distance, y = FST)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ Country1, scales = "free", ncol = 2) +
  geom_text(data = regression_results, aes(label = paste(equation, r2, sep = "\n"), x = Inf, y = Inf), 
            vjust = 2, hjust = 2, size = 3.5, inherit.aes = FALSE) +
  labs(title = "FST vs Distance by Country",
       x = "Distance",
       y = "FST") +
  scale_x_continuous(labels = scales::comma) + 
  theme_bw()


ggsave(
  filename = here("output", "fst", "fst_by_distance_countries_LD1.pdf"),
  width = 6,
  height = 8,
  units = "in"
)
```

We can merge the FST and distance matrices
```{r}
# Ensure the matrices have the same names in the same order
common_names <- intersect(rownames(distance_matrix), rownames(aa))
sorted_names <- sort(common_names)

# Reorder the matrices
distance_matrix <- distance_matrix[sorted_names, sorted_names]
aa <- aa[sorted_names, sorted_names]

# Initialize the final merged matrix
merged_matrix <- matrix(NA, nrow = nrow(aa), ncol = ncol(aa))
rownames(merged_matrix) <- sorted_names
colnames(merged_matrix) <- sorted_names

# Fill the upper triangular part from aa
merged_matrix[upper.tri(merged_matrix, diag = FALSE)] <- aa[upper.tri(aa, diag = FALSE)]

# Fill the lower triangular part from distance_matrix
merged_matrix[lower.tri(merged_matrix, diag = FALSE)] <- distance_matrix[lower.tri(distance_matrix, diag = FALSE)]

# Format the matrix (Fst two decimals and distance in Km with zero decimals)
# Format the elements based on their position in the matrix
for(i in 1:nrow(merged_matrix)) {
  for(j in 1:ncol(merged_matrix)) {
    if (i < j) {
      # Upper triangular - Fst values with two decimal places
      merged_matrix[i, j] <- sprintf("%.2f", as.numeric(merged_matrix[i, j]))
    } else if (i > j) {
      # Lower triangular - Distance values with zero decimal places
      merged_matrix[i, j] <- sprintf("%.0f", as.numeric(merged_matrix[i, j]))
    }
  }
}

# Now the merged_matrix should be formatted as you need
print(merged_matrix)
```

```{r}
cities <- readRDS(here("output", "populations", "cities.rds"))
head(cities)
```

We can sort by distance
```{r}
# Calculate row-wise mean distances (excluding diagonal)
row_means <- rowMeans(distance_matrix, na.rm=TRUE)

# Sort row names by mean distances
sorted_names_by_distance <- names(sort(row_means))

# Reorder distance_matrix and aa matrices based on these sorted names
distance_matrix <- distance_matrix[sorted_names_by_distance, sorted_names_by_distance]
aa <- aa[sorted_names_by_distance, sorted_names_by_distance]

# Your existing code to initialize and fill the merged_matrix
merged_matrix <- matrix(NA, nrow = nrow(aa), ncol = ncol(aa))
rownames(merged_matrix) <- sorted_names_by_distance
colnames(merged_matrix) <- sorted_names_by_distance

merged_matrix[upper.tri(merged_matrix, diag = FALSE)] <- aa[upper.tri(aa, diag = FALSE)]
merged_matrix[lower.tri(merged_matrix, diag = FALSE)] <- distance_matrix[lower.tri(distance_matrix, diag = FALSE)]

# Formatting code with absolute value for upper triangular part
for(i in 1:nrow(merged_matrix)) {
  for(j in 1:ncol(merged_matrix)) {
    if (i < j) {
      merged_matrix[i, j] <- sprintf("%.2f", abs(as.numeric(merged_matrix[i, j])))
    } else if (i > j) {
      merged_matrix[i, j] <- sprintf("%.0f", as.numeric(merged_matrix[i, j]))
    }
  }
}

# Print the merged matrix
print(merged_matrix)
```

Make a table and save as word document
```{r}
# Convert the matrix to a data frame and add a column with row names
merged_df <- as.data.frame(merged_matrix)
merged_df$Population <- rownames(merged_matrix)

# Reorder columns to have RowNames as the first column
merged_df <- merged_df[, c("Population", colnames(merged_matrix))]


# Create a flextable object from the merged_matrix
ft <- qflextable(as.data.frame(merged_df))

ft

# Create a new Word document
doc <- read_docx()

# Add the flextable to the Word document
doc <- body_add_flextable(doc, ft)

# Save the Word document
print(doc, target =  here("output", "fst", "LD1.docx"))
```


## 3. SNP set r2 0.1

```{r}
# Remove all objects from the environment
rm(list = ls())

# Run the garbage collector to free up memory
gc()
```


```{bash}
plink \
--allow-extra-chr \
--keep-allele-order \
--bfile output/populations/snps_sets/r2_0.1 \
--keep-fam output/fst/pops_4fst.txt \
--recodeA \
--out output/fst/r2_0.1 \
--silent;
grep 'samples\|variants\|remaining' output/fst/r2_0.1.log
```

Look at https://rdrr.io/cran/StAMPP/man/stamppFst.html for details of Fst estimations

```{r, eval=FALSE, message=FALSE, results='hide'}
r2_0.1 <-
  read.PLINK(
    here(
      "output", "fst", "r2_0.1.raw"
    ),
    quiet = FALSE,
    chunkSize = 1000,
    parallel = require("parallel"),
    n.cores = 4
  )

summary(r2_0.1)
```


This chunk will take a couple minutes to run.
```{r, eval=FALSE}
# convert
r2_0.1_2 <- stamppConvert(r2_0.1, type="genlight")

# run stampp. If you want to runn with bootstraps and nclusters use the HPC. It will run out of memory on a 32Gb laptop
r2_0.1_3 <- stamppFst(r2_0.1_2, 1, 95, 1)
```


Save it
```{r, eval=FALSE}
saveRDS(
  r2_0.1_3, here(
    "output", "fst", "r2_0.1.rds"
  )
)
```


To load it
```{r}
r2_0.1_3 <- readRDS(
  here(
    "output", "fst", "r2_0.1.rds"
  )
)
```



Now lets look at the object

```{r}
summary(r2_0.1_3)
```

If you want you can save the fst values as csv.
```{r}
# Convert to data frame
r2_0.1_df <- data.frame(r2_0.1_3)

# Save it
write.csv(r2_0.1_df, file = here("output", "fst", "r2_0.1_df.csv"))
```

Check the Fst values
```{r}
head(r2_0.1_df)
```


Now lets get the Fst values from the object albo3. It has the bootstraps, CI limits, p-values, and Fst values.
We will convert the data into a matrix.
```{r}
aa <- as.matrix(r2_0.1_df)
aa[upper.tri(aa)] <- t(aa)[upper.tri(t(aa))]
head(aa)
```

Import sample locations
```{r}
sampling_loc <- readRDS(here("output", "populations", "sampling_loc.rds"))

# Create a named vector to map countries to regions
country_to_region <- c(
  "Bhutan" = "South Asia",
  "Cambodia" = "Southeast Asia",
  "China" = "East Asia",
  "India" = "South Asia",
  "Indonesia" = "Southeast Asia",
  "Japan" = "East Asia",
  "Malaysia" = "Southeast Asia",
  "Maldives" = "South Asia",
  "Nepal" = "South Asia",
  "Sri Lanka" = "South Asia",
  "Taiwan" = "East Asia",
  "Thailand" = "Southeast Asia",
  "Vietnam" = "Southeast Asia"
)

# Add the region to the data frame
sampling_loc$Region2 <- country_to_region[sampling_loc$Country]

# Arrange by region 
sampling_loc <- sampling_loc |>
  dplyr::arrange(
    Region2, Country
  )

# Check it
head(sampling_loc)
```

Order
```{r}
order_pops <- as.vector(sampling_loc$Abbreviation)
order_pops
```

Create vector with order of populations
```{r}
# Extract the populations that appear in neutral_df
populations_in_r2_0.1 <- colnames(r2_0.1_df)

# Reorder the populations based on order_pops
poporder <- populations_in_r2_0.1[populations_in_r2_0.1 %in% order_pops]

# Print the reordered populations
print(poporder)
```


Lets check if the matrix is symmetric.
```{r}
isSymmetric(aa)
```


Now lets order the matrix using poporder. We will also add NA on the upper left side of the matrix.
```{r}
aa <- aa[poporder, poporder]
aa[lower.tri(aa)] <- NA
```


Now we have to convert the matrix to a data frame to plot it with ggplot.

```{r}
pairfst.long <- melt(aa)
summary(pairfst.long)
```

Now lets plot the data with ggplot.
You can click in the little square on the top left of the plot to open it on a new window. It will have the right proportions.
```{r, fig.width=9, fig.height=8}
pairfst.f <- ggplot(pairfst.long, aes(Var1, Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  scale_fill_gradient(
    low = "white",
    high = "#71b6ff",
    name = "Fst",
    na.value = "white",
    limits = c(0, 0.5)
  ) +
  scale_x_discrete(position = "top") +
  theme_bw() +
  geom_text(aes(label = ifelse(
    is.na(value), "", formatC(value, digits = 2, format = "f")
  )), size = 3) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_text(hjust = 0)
  )
pairfst.f
```

```{r}
ggsave(
  filename = here("output", "fst", "fst_matrix_r2_0.1.pdf"),
  pairfst.f,
  width = 10,
  height = 10,
  units = "in"
)
```

By country
```{r}
# Step 1: Map abbreviation to country
abbreviation_to_country <- sampling_loc %>% select(Abbreviation, Country)

# Step 2: Calculate mean Fst for each pair of countries

# Convert the matrix to a data frame and add row names as a new column
fst_df <- as.data.frame(as.matrix(r2_0.1_df))
fst_df$Abbreviation1 <- rownames(fst_df)

# Gather columns into rows
fst_long <- fst_df %>% gather(key = "Abbreviation2", value = "Fst", -Abbreviation1)

# Merge with country mapping
fst_long <- merge(fst_long, abbreviation_to_country, by.x = "Abbreviation1", by.y = "Abbreviation")
fst_long <- merge(fst_long, abbreviation_to_country, by.x = "Abbreviation2", by.y = "Abbreviation", suffixes = c("_1", "_2"))

# Calculate mean Fst for each pair of countries
fst_summary <- fst_long %>% 
  group_by(Country_1, Country_2) %>% 
  summarize(Mean_Fst = mean(Fst, na.rm = TRUE), .groups = 'drop') %>% 
  filter(Country_1 != Country_2)

# Convert summary back to a matrix form, avoiding the use of tibbles for row names
fst_matrix_summary <- as.data.frame(spread(fst_summary, key = Country_2, value = Mean_Fst))
rownames(fst_matrix_summary) <- fst_matrix_summary$Country_1
fst_matrix_summary <- fst_matrix_summary[, -1]
fst_matrix_summary <- as.matrix(fst_matrix_summary)

# Make the matrix symmetric by averaging the off-diagonal elements
symmetric_fst_matrix <- matrix(nrow = nrow(fst_matrix_summary), ncol = ncol(fst_matrix_summary))
rownames(symmetric_fst_matrix) <- rownames(fst_matrix_summary)
colnames(symmetric_fst_matrix) <- colnames(fst_matrix_summary)

for(i in 1:nrow(fst_matrix_summary)) {
  for(j in i:nrow(fst_matrix_summary)) {
    if (i == j) {
      symmetric_fst_matrix[i, j] <- fst_matrix_summary[i, j]
    } else {
      avg_value <- mean(c(fst_matrix_summary[i, j], fst_matrix_summary[j, i]), na.rm = TRUE)
      symmetric_fst_matrix[i, j] <- avg_value
      symmetric_fst_matrix[j, i] <- avg_value
    }
  }
}

# Check if the matrix is symmetric
# print(isSymmetric(symmetric_fst_matrix))

# Your symmetric Fst matrix by country is now in symmetric_fst_matrix
print(symmetric_fst_matrix)
```


```{r}
symmetric_fst_matrix[lower.tri(symmetric_fst_matrix)] <- NA
print(symmetric_fst_matrix)
```


Now we have to convert the matrix to a data frame to plot it with ggplot.

```{r}
pairfst.long2 <- melt(symmetric_fst_matrix)
summary(pairfst.long2)
```

You can click in the little square on the top left of the plot to open it on a new window. It will have the right proportions.
```{r, fig.width=6, fig.height=5}
pairfst.f2 <- ggplot(pairfst.long2, aes(Var1, Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  scale_fill_gradient(
    low = "white",
    high = "orange",
    name = "Fst",
    na.value = "white",
    limits = c(0, 0.5)
  ) +
  scale_x_discrete(position = "top") +
  theme_bw() +
  geom_text(aes(label = ifelse(
    is.na(value), "", formatC(value, digits = 2, format = "f")
  )), size = 3) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0),
    axis.title = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_text(hjust = 1)
  )
pairfst.f2

ggsave(
  filename = here("output", "fst", "fst_matrix_r2_0.1_by_country.pdf"),
  pairfst.f2, 
  width = 6,
  height = 5,
  units = "in"
)
```

Remove NAs and rename columns
```{r}
# remove NAs
fst2 <-
  pairfst.long |>
  drop_na()

# rename columns
fst2 <-
  fst2 |>
  dplyr::rename(pop1 = 1,
         pop2 = 2,
         fst  = 3)


# Split the data into two data frames, one for pop1 and one for pop2
df_pop1 <- fst2 |>
  dplyr::select(pop = pop1, fst)
df_pop2 <- fst2 |>
  dplyr::select(pop = pop2, fst)

# Combine the two data frames
df_combined <- bind_rows(df_pop1, df_pop2)

# Calculate the mean fst for each population
mean_fst <- df_combined |>
  group_by(pop) |>
  summarise(mean_fst = mean(fst))

print(mean_fst)
```

Merge
```{r}
fst3 <-
  sampling_loc |>
  left_join(
    mean_fst,
    by = c("Abbreviation" = "pop")
  ) |>
  drop_na() |>
  dplyr::select(
    -Region
  )

# Remove " Asia" from the Region2 column
fst3$Region2 <- gsub(" Asia", "", fst3$Region2)

# Rename the Region2 column to Region
fst3 <- fst3 |>
  dplyr::rename(Region = Region2)

# check output
head(fst3)
```

Mean by region
```{r}
# Group by Region and calculate the mean_fst by Region
region_means <- fst3 |>
  group_by(Region) |>
  summarize(mean_fst_by_region = round(mean(mean_fst, na.rm = TRUE), 2)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_region column to the fst3 tibble
fst3 <- fst3 |>
  left_join(region_means, by = "Region")

# Print the modified fst3 tibble
print(fst3)
```

Mean by country
```{r}
# Group by Country and calculate the mean_fst by Country
country_means <- fst3 |>
  group_by(Country) |>
  summarize(mean_fst_by_country = round(mean(mean_fst, na.rm = TRUE), 2)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_country column to the fst3 tibble
fst3 <- fst3 |>
  left_join(country_means, by = "Country")

# Print the modified fst3 tibble
print(fst3)
```

Mean by latitude
```{r}
# Add a new column to indicate whether the latitude is above or below 30N
fst3 <- fst3 |>
  mutate(Latitude_group = ifelse(Latitude >= 30, "Above 30N", "Below 30N"))

# Summarize the data by Latitude_group and calculate the mean_fst
summary_by_latitude <- fst3 |>
  group_by(Latitude_group) |>
  summarize(mean_fst_by_latitude = mean(mean_fst, na.rm = TRUE)) |>
  ungroup()  # Ungroup the data

# Add the mean_fst_by_latitude column to the fst3 tibble
fst3 <- fst3 |>
  left_join(summary_by_latitude, by = "Latitude_group")


# Rename columns
fst3 <- fst3 |>
  dplyr::rename(
    City = Pop_City
  )

# Print the modified fst3 tibble
print(fst3)
```

```{r}
fst4 <- fst3 |>
  dplyr::select(
    Latitude_group, mean_fst_by_latitude, Region, mean_fst_by_region, Country, mean_fst_by_country, City, Abbreviation, mean_fst,
  )

fst4 <- fst4 |>
  arrange(
    Latitude_group, Region, Country, City
  )

# Round
fst4 <- fst4 |>
  mutate_if(is.numeric, ~ round(., 2))

head(fst4)
```


```{r}
# Set theme if you want to use something different from the previous table
set_flextable_defaults(
  font.family = "Arial",
  font.size = 9,
  big.mark = ",",
  theme_fun = "theme_zebra" # try the themes: theme_alafoli(), theme_apa(), theme_booktabs(), theme_box(), theme_tron_legacy(), theme_tron(), theme_vader(), theme_vanilla(), theme_zebra()
)

# Then create the flextable object
flex_table <- flextable(fst4) |>
  set_caption(caption = as_paragraph(
    as_chunk(
      "Table 1. Fst values using SNPs after prunning with r2 0.1.",
      props = fp_text_default(color = "#000000", font.size = 14)
    )
  ),
  fp_p = fp_par(text.align = "center", padding = 5))

# Print the flextable
flex_table
```

```{r}
# Initialize Word document
doc <- 
  read_docx() |>
  body_add_flextable(value = flex_table)

# Define the output path with 'here' library
output_path <- here(
  "output",
  "fst", 
  "fst_r2_0.1_SNPS.docx"
  )

# Save the Word document
print(doc, target = output_path)
```


To make scatter plot
```{r}
# Group by Country and calculate the mean for mean_fst_by_country
aggregated_data <- fst4 |>
  dplyr::group_by(Country) |>
  dplyr::summarise(mean_fst = mean(mean_fst_by_country, na.rm = TRUE))

# save the data
saveRDS(aggregated_data, here(
  "output", "fst", "r2_0.1_country.rds"
))

# Order the aggregated data
aggregated_data <- aggregated_data[order(aggregated_data$mean_fst), ]

# Assign a numeric index for plotting
aggregated_data$index <- 1:nrow(aggregated_data)

# Fit a linear model
lm_fit <- lm(mean_fst ~ index, data = aggregated_data)

# Predicted values from the linear model
aggregated_data$fitted_values <- predict(lm_fit)

ggplot(aggregated_data, aes(x = index, y = mean_fst)) +
  geom_point(aes(color = Country), size = 3) +
  geom_line(aes(y = fitted_values), color = "blue") +  # Fitted line
  labs(
    title = "Mean Fst by Country",
    x = "Ordered Countries",
    y = "Mean Fst Value"
  ) +
  scale_x_continuous(breaks = aggregated_data$index, labels = aggregated_data$Country) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")
```

Estimate distances
```{r}
# Grab the population names from the matrix aa
populations_with_fst <- colnames(aa)

# Subset the sampling_loc dataframe to only include populations with FST estimates
filtered_sampling_loc <- sampling_loc %>% filter(Abbreviation %in% populations_with_fst)

# Create an empty matrix to store the distances
n <- nrow(filtered_sampling_loc)
distance_matrix <- matrix(0, n, n)
rownames(distance_matrix) <- filtered_sampling_loc$Abbreviation
colnames(distance_matrix) <- filtered_sampling_loc$Abbreviation

# Calculate the distances
for (i in 1:n) {
  for (j in 1:n) {
    if (i != j) {
      coord1 <- c(filtered_sampling_loc$Longitude[i], filtered_sampling_loc$Latitude[i])
      coord2 <- c(filtered_sampling_loc$Longitude[j], filtered_sampling_loc$Latitude[j])
      distance_matrix[i, j] <- distHaversine(coord1, coord2) / 1000 # distance in km
    }
  }
}

# Print the distance matrix
head(distance_matrix)
```


Compare distance and FST

```{r}
# Fill lower triangle of 'aa' matrix
aa[lower.tri(aa)] <- t(aa)[lower.tri(aa)]

# Fill diagonal with 0 (or another value that makes sense in your context)
diag(aa) <- 0


# Combine 'aa' and 'distance_matrix'
data <- data.frame(Distance = as.vector(distance_matrix), FST = as.vector(aa))

# Add row and column indices for easier tracking
data$row_index <- rep(rownames(distance_matrix), each = ncol(distance_matrix))
data$col_index <- rep(colnames(distance_matrix), nrow(distance_matrix))

head(data)
```

Fit linear regression
```{r, fig.height=4, fig.width=6}
# Fit linear model
lm_model <- lm(FST ~ Distance, data = data)
equation_text <- sprintf("y = %.6fx + %.3f", coef(lm_model)[2], coef(lm_model)[1])
r2_text <- sprintf("R^2 = %.2f", summary(lm_model)$r.squared)

# source the plotting function
source(here("scripts", "analysis", "my_theme2.R"))


# Plot
ggplot(data, aes(x = Distance, y = FST)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  annotate("text", x = max(data$Distance) * 0.85, y = max(data$FST) * 0.95, label = paste(equation_text, r2_text, sep = "\n"), size = 4, color = "black") +
  labs(title = "FST vs Distance - All populations",
       x = "Distance (Km)",
       y = "FST") +
  scale_x_continuous(labels = scales::comma) + 
  theme_classic()

ggsave(
  filename = here("output", "fst", "fst_by_distance_all_samples_LD2.pdf"),
  width = 6,
  height = 4,
  units = "in"
)
```


Subset by country
Select coutries with at least 3 sampling localities
```{r}
countries_with_3_pops <- filtered_sampling_loc %>%
  group_by(Country) %>%
  filter(n() >= 3) %>%
  pull(Country) %>%
  unique()
countries_with_3_pops
```

Do test for each country
```{r}
results <- list()

for (country in countries_with_3_pops) {
  # Extract abbreviations for the country
  abbreviations <- filtered_sampling_loc %>%
    filter(Country == country) %>%
    pull(Abbreviation)
  
  # Subset the data
  subset_data <- data %>%
    filter(row_index %in% abbreviations & col_index %in% abbreviations)
  
  # Perform linear regression
  lm_model <- lm(FST ~ Distance, data = subset_data)
  results[[country]] <- list(
    equation = sprintf("y = %.5fx + %.3f", coef(lm_model)[2], coef(lm_model)[1]),
    r2 = sprintf("R^2 = %.2f", summary(lm_model)$r.squared)
  )
}

results
```

Merge the data
```{r}
data_merged <- data %>%
  left_join(filtered_sampling_loc[, c("Pop_City", "Country", "Abbreviation")], by = c("row_index" = "Abbreviation")) %>%
  rename(Country1 = Country) %>%
  left_join(filtered_sampling_loc[, c("Pop_City", "Country", "Abbreviation")], by = c("col_index" = "Abbreviation")) %>%
  select(-Pop_City.x, -Pop_City.y) %>%
  filter(Country1 == Country)  # Ensures the data is within the same country


# Filter to get the coutries with 3 or more sampling localities
countries_to_include <- c("China", "Japan", "Indonesia", "Thailand", "Vietnam")

# Filter
data_filtered <- data_merged %>%
  group_by(Country1) %>%
  filter(n() >= 3 & Country1 %in% countries_to_include) %>%
  ungroup()
```

Calculate the linear regression for each country
```{r}
regression_results <- data_filtered %>%
  group_by(Country1) %>%
  do(model = lm(FST ~ Distance, data = .)) %>%
  rowwise() %>%
  mutate(equation = sprintf("y = %.3fx + %.3f", coef(model)[2], coef(model)[1]),
         r2 = sprintf("R^2 = %.2f", summary(model)$r.squared))
```

Plot it
```{r, fig.height=8, fig.width=6}
ggplot(data_filtered, aes(x = Distance, y = FST)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ Country1, scales = "free", ncol = 2) +
  geom_text(data = regression_results, aes(label = paste(equation, r2, sep = "\n"), x = Inf, y = Inf), 
            vjust = 2, hjust = 2, size = 3.5, inherit.aes = FALSE) +
  labs(title = "FST vs Distance by Country",
       x = "Distance",
       y = "FST") +
  scale_x_continuous(labels = scales::comma) + 
  theme_bw()


ggsave(
  filename = here("output", "fst", "fst_by_distance_countries_LD2.pdf"),
  width = 6,
  height = 8,
  units = "in"
)
```

We can merge the FST and distance matrices
```{r}
# Ensure the matrices have the same names in the same order
common_names <- intersect(rownames(distance_matrix), rownames(aa))
sorted_names <- sort(common_names)

# Reorder the matrices
distance_matrix <- distance_matrix[sorted_names, sorted_names]
aa <- aa[sorted_names, sorted_names]

# Initialize the final merged matrix
merged_matrix <- matrix(NA, nrow = nrow(aa), ncol = ncol(aa))
rownames(merged_matrix) <- sorted_names
colnames(merged_matrix) <- sorted_names

# Fill the upper triangular part from aa
merged_matrix[upper.tri(merged_matrix, diag = FALSE)] <- aa[upper.tri(aa, diag = FALSE)]

# Fill the lower triangular part from distance_matrix
merged_matrix[lower.tri(merged_matrix, diag = FALSE)] <- distance_matrix[lower.tri(distance_matrix, diag = FALSE)]

# Format the matrix (Fst two decimals and distance in Km with zero decimals)
# Format the elements based on their position in the matrix
for(i in 1:nrow(merged_matrix)) {
  for(j in 1:ncol(merged_matrix)) {
    if (i < j) {
      # Upper triangular - Fst values with two decimal places
      merged_matrix[i, j] <- sprintf("%.2f", as.numeric(merged_matrix[i, j]))
    } else if (i > j) {
      # Lower triangular - Distance values with zero decimal places
      merged_matrix[i, j] <- sprintf("%.0f", as.numeric(merged_matrix[i, j]))
    }
  }
}

# Now the merged_matrix should be formatted as you need
print(merged_matrix)
```

```{r}
cities <- readRDS(here("output", "populations", "cities.rds"))
head(cities)
```

We can sort by distance
```{r}
# Calculate row-wise mean distances (excluding diagonal)
row_means <- rowMeans(distance_matrix, na.rm=TRUE)

# Sort row names by mean distances
sorted_names_by_distance <- names(sort(row_means))

# Reorder distance_matrix and aa matrices based on these sorted names
distance_matrix <- distance_matrix[sorted_names_by_distance, sorted_names_by_distance]
aa <- aa[sorted_names_by_distance, sorted_names_by_distance]

# Your existing code to initialize and fill the merged_matrix
merged_matrix <- matrix(NA, nrow = nrow(aa), ncol = ncol(aa))
rownames(merged_matrix) <- sorted_names_by_distance
colnames(merged_matrix) <- sorted_names_by_distance

merged_matrix[upper.tri(merged_matrix, diag = FALSE)] <- aa[upper.tri(aa, diag = FALSE)]
merged_matrix[lower.tri(merged_matrix, diag = FALSE)] <- distance_matrix[lower.tri(distance_matrix, diag = FALSE)]

# Formatting code with absolute value for upper triangular part
for(i in 1:nrow(merged_matrix)) {
  for(j in 1:ncol(merged_matrix)) {
    if (i < j) {
      merged_matrix[i, j] <- sprintf("%.2f", abs(as.numeric(merged_matrix[i, j])))
    } else if (i > j) {
      merged_matrix[i, j] <- sprintf("%.0f", as.numeric(merged_matrix[i, j]))
    }
  }
}

# Print the merged matrix
print(merged_matrix)
```

Make a table and save as word document
```{r}
# Convert the matrix to a data frame and add a column with row names
merged_df <- as.data.frame(merged_matrix)
merged_df$Population <- rownames(merged_matrix)

# Reorder columns to have RowNames as the first column
merged_df <- merged_df[, c("Population", colnames(merged_matrix))]


# Create a flextable object from the merged_matrix
ft <- qflextable(as.data.frame(merged_df))

ft

# Create a new Word document
doc <- read_docx()

# Add the flextable to the Word document
doc <- body_add_flextable(doc, ft)

# Save the Word document
print(doc, target =  here("output", "fst", "LD2.docx"))
```

## 4. Comparison of the 3 sets


```{r}
# Remove all objects from the environment
rm(list = ls())

# Run the garbage collector to free up memory
gc()
```

Import the data

Intergenic
```{r}
intergenic <- readRDS(
  here(
    "output", "fst", "neutral_country.rds"
  )
)
head(intergenic)
```

LD1
```{r}
LD1 <- readRDS(
  here(
    "output", "fst", "r2_0.01_country.rds"
  )
)
head(LD1)
```

LD2
```{r}
LD2 <- readRDS(
  here(
    "output", "fst", "r2_0.1_country.rds"
  )
)
head(LD2)
```


Merge the data sets
```{r, fig.height=5, fig.width=7}
# Add an identifier column to each dataset
intergenic$dataset <- "intergenic"
LD1$dataset <- "LD1"
LD2$dataset <- "LD2"

# Merge the datasets
combined_data <- rbind(intergenic, LD1, LD2)

# Assign a numeric index for plotting based on ordered countries
combined_data <- combined_data %>% 
  arrange(Country) %>%
  group_by(Country) %>%
  mutate(index = dense_rank(Country))

# Custom color mapping
color_mapping <- scale_color_manual(
  values = c(intergenic = "gray", LD1 = "blue", LD2 = "orange"),
  name = "Dataset"
)


# Shapes
shape_mapping <- scale_shape_manual(
  values = c(intergenic = 16, LD1 = 17, LD2 = 18),
  name = "Dataset"
)


# Scatter plot with custom colors and shapes
plot <- ggplot(combined_data, aes(x = Country, y = mean_fst, color = dataset, shape = dataset)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, aes(group = dataset)) +  # Fitted line per dataset
  labs(
    title = "",
    x = "Countries",
    y = "Mean Fst"
  ) +
  color_mapping +
  shape_mapping +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "top")

# Display the plot
print(plot)

ggsave(
  filename = here("output", "fst", "fst_datasets_country.pdf"),
  plot, 
  width = 7,
  height = 5,
  units = "in"
)
```


## 5. Mantel test with LD2

```{bash, eval=FALSE}
plink \
--allow-extra-chr \
--keep-allele-order \
--bfile output/populations/snps_sets/r2_0.1 \
--keep-fam output/fst/pops_4fst.txt \
--make-bed \
--out output/fst/mantel \
--silent;
grep 'samples\|variants\|remaining' output/fst/mantel.log
```

Then make sure to edit the line "BEN a 0 0 0 -9" to "BEN b 0 0 0 -9"

Then convert to raw format
```{bash, eval=FALSE}
plink \
--allow-extra-chr \
--keep-allele-order \
--bfile output/fst/mantel \
--recodeA \
--out output/fst/mantel \
--silent;
grep 'samples\|variants\|remaining' output/fst/mantel.log
```


Import the daat and covert it to genind format
```{r eval=FALSE}
# import the data
albo <-
  read.PLINK(
    here("output", "fst", "mantel.raw"),
    quiet = FALSE,
    chunkSize = 1000,
    parallel = require("parallel"),
    n.cores = 4
  )

# convert to genind
albo2 <- gl2gi(albo, probar = TRUE, verbose = NULL)
```

```{r, eval=FALSE}
saveRDS(albo2, here(
  "output", "fst", "albo2.rds"
))
```

Load it
```{r}
albo2 <- readRDS(here(
  "output", "fst", "albo2.rds"
))
```

Import sample locations
```{r}
sampling_loc <- readRDS(here("output", "populations", "cities.rds"))
head(sampling_loc)
```

The fam file
```{r}
fam_file <- here(
  "output", "fst", "mantel.fam"
)

# Read the .fam file
fam_data <- read.table(fam_file, 
                       header = FALSE,
                       col.names = c("FamilyID", "IndividualID", "PaternalID", "MaternalID", "Sex", "Phenotype"))

# # Replace the BEN a with BEN b (remember to never name samples with the same ID... I change it manually in the fam file.)
# fam_data <- fam_data %>% 
#   mutate(IndividualID = ifelse(FamilyID == "BEN" & IndividualID == "a", "b", IndividualID))

# View the first few rows
head(fam_data)
```

Merge
```{r}
# Join with sampling_loc to get sampling localities
loc_albo <- fam_data |>
  left_join(sampling_loc, by = c("FamilyID" = "Abbreviation"))

head(loc_albo)
```

Get the latitude and longitude
```{r}
albo_dist2 <- cbind(loc_albo$Latitude, loc_albo$Longitude)
head(albo_dist2)
colnames(albo_dist2)<- c("x","y") 
```

Add jitter
```{r}
albo_dist2 <- jitter(albo_dist2, factor = 1, amount = NULL)
head(albo_dist2)
```


Add to object
```{r}
albo2$other$xy <- albo_dist2
```

Save
```{r}
saveRDS(
  albo2,
  here(
    "output", "fst", "albo2.rds"
  )
)
```


Isolation by distance
```{r}
# Calculate distances
# Genetic
Dgen <- dist(albo2$tab)

# Physical
Dgeo <- dist(other(albo2)$xy)

# Run the Mantel test is a statistical test to compare two matrices and check if they are correlated. In this context, it's used to check if genetic distance (Dgen) correlates with geographic distance (Dgeo). The .randtest variant performs a randomized version of the test to estimate the significance of the observed correlation.
ibd <- mantel.randtest(Dgen,Dgeo)

# Check it
ibd
```


Simulated p-value: 0.001
This is a very low p-value, suggesting that the observed correlation between genetic and geographic distance is statistically significant, and it's unlikely to have arisen by random chance.
Alternative hypothesis: greater
The test was one-sided, checking if the observed correlation is greater than what would be expected by chance.


Plot 
```{r}
# Plot it
# Start the PDF device
CairoPDF(here(
     "output", "fst", "sim.pdf"))
plot(ibd)
dev.off()
plot(ibd)
```

```{r}
plot(Dgeo, Dgen)
# A linear regression model (lm stands for "linear model") is fitted, with the genetic distances (Dgen) as the response variable and the geographic distances (Dgeo) as the predictor. The distances are transformed into vectors using as.vector because the dist function produces a matrix-like structure, but the linear regression function lm requires vectors.
dist_lm <- lm(as.vector(Dgen) ~ as.vector(Dgeo))
abline(dist_lm, col="red", lty=2)
```

Add the equation
```{r}
# Plotting the data
plot(Dgeo, Dgen, main = "Genetic Distance vs Geographic Distance")
abline(dist_lm, col="red", lty=2)

# Extracting the coefficients from the linear model
intercept <- coef(dist_lm)[1]
slope <- coef(dist_lm)[2]
r2 <- summary(dist_lm)$r.squared

# Generating the equation string
equation <- sprintf("y = %.2fx + %.2f", slope, intercept)
r2_label <- sprintf("R^2 = %.2f", r2)

# Adding the equation and R^2 to the plot
# You can adjust the position (e.g., x and y values) as necessary
text(x = max(as.vector(Dgeo)) * 0.8, y = max(as.vector(Dgen)) * 0.9, labels = equation)
text(x = max(as.vector(Dgeo)) * 0.8, y = max(as.vector(Dgen)) * 0.85, labels = r2_label)

```



Use library MASS for plot
```{r}
dens <- kde2d(as.vector(Dgeo), as.vector(Dgen), n = 500)
myPal <-
  colorRampPalette(c("white", "blue", "gold", "orange", "red"))
# CairoPDF(here("output", "fst", "ibd.pdf"),
#     width = 5,
#     height = 4)
# png(here("output", "fst", "ibd2.png"),
#     width = 5,
#     height = 4,
#     units='in',
#     res = 300)
myPal <-
  colorRampPalette(c("white", "purple", "gold", "orange", "red"))
plot(Dgeo, Dgen, pch = 20, cex = .3, bty = "n")
image(dens, col = transp(myPal(300), .7), add = TRUE)
abline(dist_lm)
# Extracting the coefficients and R^2 from the linear model
intercept <- coef(dist_lm)[1]
slope <- coef(dist_lm)[2]
r2 <- summary(dist_lm)$r.squared

# Constructing the equation and R^2 strings
equation <- sprintf("y = %.2fx + %.2f", slope, intercept)
r2_label <- sprintf("R^2 = %.2f", r2)

# Adding the equation and R^2 to the plot
text(x = max(as.vector(Dgeo)) * 0.8, y = max(as.vector(Dgen)) * 0.5, labels = equation)
text(x = max(as.vector(Dgeo)) * 0.8, y = max(as.vector(Dgen)) * 0.45, labels = r2_label)

title("Isolation by distance")
# dev.off()
```

Check the populations - I did not include those with less than 4 mosquitoes
```{r}
summary(albo2$pop)
```
